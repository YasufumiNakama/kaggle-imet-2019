{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n",
    "import datetime as dt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "import torchvision as vision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from contextlib import contextmanager\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from fastprogress import master_bar, progress_bar\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_torch(seed=1234):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_torch(seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logger():\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    # handler1\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(asctime)s %(levelname)8s %(message)s\"))\n",
    "    # handler2\n",
    "    handler2 = FileHandler(filename=dt.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")+\".log\")\n",
    "    handler2.setFormatter(Formatter(\"%(asctime)s %(levelname)8s %(message)s\"))\n",
    "    # addHandler\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "logger = get_logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Csv Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels.csv  sample_submission.csv  test  train\ttrain.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../input/imet-2019-fgvc6/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>attribute_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000483014d91860</td>\n",
       "      <td>147 616 813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000fe2e667721fe</td>\n",
       "      <td>51 616 734 813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001614cb89646ee</td>\n",
       "      <td>776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10041eb49b297c08</td>\n",
       "      <td>51 671 698 813 1092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100501c227f8beea</td>\n",
       "      <td>13 404 492 903 1093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id        attribute_ids\n",
       "0  1000483014d91860          147 616 813\n",
       "1  1000fe2e667721fe       51 616 734 813\n",
       "2  1001614cb89646ee                  776\n",
       "3  10041eb49b297c08  51 671 698 813 1092\n",
       "4  100501c227f8beea  13 404 492 903 1093"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv(\"../input/imet-2019-fgvc6/labels.csv\")\n",
    "train = pd.read_csv(\"../input/imet-2019-fgvc6/train.csv\")\n",
    "sample = pd.read_csv(\"../input/imet-2019-fgvc6/sample_submission.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1103\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attribute_id</th>\n",
       "      <th>attribute_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>culture::abruzzi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>culture::achaemenid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>culture::aegean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>culture::afghan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>culture::after british</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   attribute_id          attribute_name\n",
       "0             0        culture::abruzzi\n",
       "1             1     culture::achaemenid\n",
       "2             2         culture::aegean\n",
       "3             3         culture::afghan\n",
       "4             4  culture::after british"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(labels.attribute_id.nunique())\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet18_0.562.pth\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../input/imet-my-pretrained-models/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n",
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "\n",
    "input_size = 224\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_transforms[\"test\"] = data_transforms[\"val\"]\n",
    "\n",
    "# Without KFold, We won't use data_transforms[\"val\"] this time...\n",
    "# We will use data_transforms[\"train\"] for \"..input/train\" folders, data_transforms[\"test\"] for \"..input/test\" folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMetDataset(data.Dataset):\n",
    "    def __init__(self, datafolder, datatype='train', index=[], device=\"cuda:0\",\n",
    "                 transform=transforms.Compose([transforms.CenterCrop(32),transforms.ToTensor()]), \n",
    "                 labels_dict={}):\n",
    "        self.datafolder = datafolder\n",
    "        self.datatype = datatype\n",
    "        self.index = index\n",
    "        self.device = device\n",
    "        self.transform = transform\n",
    "        self.labels_dict = labels_dict\n",
    "        if self.datatype == 'train' or self.datatype == 'val':\n",
    "            if self.index==[]:\n",
    "                self.image_files_list = [s for s in os.listdir(datafolder)]\n",
    "                #self.labels = [labels_dict[i.split('.')[0]] for i in self.image_files_list]\n",
    "            else:\n",
    "                self.image_files_list = np.array([s for s in os.listdir(datafolder)])[index]\n",
    "                #self.labels = [labels_dict[i.split('.')[0]] for i in self.image_files_list]\n",
    "        else:\n",
    "            self.image_files_list = [s for s in os.listdir(datafolder)]\n",
    "            #self.labels = [labels_dict[i.split('.')[0]] for i in self.image_files_list]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_files_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.datafolder, self.image_files_list[idx])\n",
    "        image = Image.open(img_name)\n",
    "        image = self.transform(image)\n",
    "        img_name_short = self.image_files_list[idx].split('.')[0]\n",
    "        if self.datatype == 'train' or self.datatype == 'val':\n",
    "            label = self.labels_dict[img_name_short]\n",
    "            # Target has some labels, So we need to change labels to tensor\n",
    "            label_tensor = torch.zeros((1, 1103))\n",
    "            for i in label:\n",
    "                label_tensor[0, int(i)] = 1\n",
    "            label_tensor = label_tensor.to(self.device)\n",
    "            return image, label_tensor\n",
    "        else:\n",
    "            label = 0\n",
    "            return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictioner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictioner:\n",
    "    def __init__(self, model, valid_batch=128, seed=1234, \n",
    "                 device=\"cuda:0\", load_model_name=\"best_model.pth\"):\n",
    "        self.model = model\n",
    "        self.load_model_name = load_model_name\n",
    "        self.valid_batch = valid_batch\n",
    "        self.seed = seed\n",
    "        self.device = device\n",
    "\n",
    "    def val(self, val_idx, img_class_dict):\n",
    "        # valid loader\n",
    "        valid_dataset = IMetDataset(datafolder='../input/imet-2019-fgvc6/train/', \n",
    "                                    datatype='val', \n",
    "                                    index=val_idx, \n",
    "                                    transform=data_transforms[\"val\"], \n",
    "                                    labels_dict=img_class_dict)\n",
    "        loader = data.DataLoader(valid_dataset,\n",
    "                                 batch_size=self.valid_batch,\n",
    "                                 shuffle=False)\n",
    "        # model\n",
    "        model = self.model\n",
    "        # load model pth\n",
    "        model.load_state_dict(torch.load(self.load_model_name))\n",
    "        model.to(self.device)\n",
    "        model.eval()\n",
    "        valid_preds = np.zeros((len(loader.dataset), 1103))\n",
    "        valid_y = np.zeros((len(loader.dataset), 1103))\n",
    "        avg_val_loss = 0.0\n",
    "        for i, (i_batch, y_batch) in enumerate(loader):\n",
    "            with torch.no_grad():\n",
    "                y_pred = model(i_batch.cuda()).detach()\n",
    "                y_batch = y_batch.view(y_batch.size()[0], -1) # flatten y_batch\n",
    "                #avg_val_loss += self.loss_fn(y_pred, y_batch).item() / len(loader)\n",
    "                if i_batch.size()[0]==self.valid_batch:\n",
    "                    valid_preds[i * self.valid_batch : (i+1) * self.valid_batch] = y_pred.cpu().numpy()\n",
    "                    valid_y[i * self.valid_batch : (i+1) * self.valid_batch] = y_batch.cpu().numpy()\n",
    "                else:\n",
    "                    valid_preds[len(loader.dataset) - i_batch.size()[0] : ] = y_pred.cpu().numpy()\n",
    "                    valid_y[len(loader.dataset) - i_batch.size()[0] : ] = y_batch.cpu().numpy()\n",
    "        return valid_preds, valid_y#, avg_val_loss\n",
    "    \n",
    "    def predict(self, loader):\n",
    "        model = self.model\n",
    "        # load model pth\n",
    "        model.load_state_dict(torch.load(self.load_model_name))\n",
    "        model.to(self.device)\n",
    "        model.eval()\n",
    "        preds = np.zeros((len(loader.dataset), 1103))\n",
    "        for i, (i_batch, _) in enumerate(loader):\n",
    "            with torch.no_grad():\n",
    "                y_pred = model(i_batch.cuda()).detach()\n",
    "                if i_batch.size()[0]==self.valid_batch:\n",
    "                    preds[i * self.valid_batch : (i+1) * self.valid_batch] = y_pred.cpu().numpy()\n",
    "                else:\n",
    "                    preds[len(loader.dataset) - i_batch.size()[0] : ] = y_pred.cpu().numpy()\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        width = int(planes * (base_width / 64.)) * groups\n",
    "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv1x1(inplanes, width)\n",
    "        self.bn1 = norm_layer(width)\n",
    "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
    "        self.bn3 = norm_layer(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
    "                 norm_layer=None):\n",
    "        super(ResNet, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def resnet18(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv = resnet18(pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "#model_conv.fc = nn.Linear(num_ftrs, 1103)\n",
    "model_conv.fc = Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP\n",
    "mlp = nn.Sequential(\n",
    "    nn.Linear(num_ftrs, num_ftrs),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(num_ftrs),\n",
    "    nn.Dropout(0.25),\n",
    "    nn.Linear(num_ftrs, 1103)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    model_conv,\n",
    "    mlp,\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictioner = Predictioner(net, valid_batch=128, seed=1234, device=\"cuda:0\", \n",
    "                            load_model_name=\"../input/imet-my-pretrained-models/resnet18_0.562.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices for validation\n",
    "tr, val = train_test_split(train.id, test_size=0.2, random_state=1234)\n",
    "tr, val = tr.index, val.index\n",
    "#tr, val = list(tr), list(val)\n",
    "# X_train, y_train, X_val, y_val\n",
    "img_class_dict = {k:v for k, v in zip(train.id, train.attribute_ids.map(lambda x: x.split()).values)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_preds, valid_y = predictioner.val(val, img_class_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post process - threshold search -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_search(y_pred, y_true):\n",
    "    score = []\n",
    "    candidates = np.arange(0, 0.4, 0.01)\n",
    "    for th in progress_bar(candidates):\n",
    "        yp = (y_pred > th).astype(int)\n",
    "        score.append(fbeta_score(y_pred=yp, y_true=y_true, beta=2, average=\"samples\"))\n",
    "    score = np.array(score)\n",
    "    pm = score.argmax()\n",
    "    best_th, best_score = candidates[pm], score[pm]\n",
    "    plt.plot(candidates, score)\n",
    "    plt.vlines(x=best_th, ymin=score.min(), ymax=score.max())\n",
    "    plt.text(best_th+0.03, best_score-0.01, f'$F_{2}=${best_score:.3f}', fontsize=14);\n",
    "    plt.show()\n",
    "    return best_th, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='40' class='' max='40', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [40/40 01:21<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_threshold, best_score = threshold_search(valid_preds, valid_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test loader\n",
    "test_dataset = IMetDataset(datafolder='../input/imet-2019-fgvc6/test/', \n",
    "                           datatype='test', \n",
    "                           transform=data_transforms[\"test\"])\n",
    "test_loader = data.DataLoader(test_dataset,\n",
    "                              batch_size=128,\n",
    "                              shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = predictioner.predict(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = (test_preds > best_threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>attribute_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10023b2cc4ed5f68</td>\n",
       "      <td>195 223 289 344 369 587 766 1039 1059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100fbe75ed8fd887</td>\n",
       "      <td>231 1039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101b627524a04f19</td>\n",
       "      <td>79 263 420 498 784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10234480c41284c6</td>\n",
       "      <td>13 147 553 738 776 830 1006 1046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1023b0e2636dcea8</td>\n",
       "      <td>147 283 322 584 698 813 896 954 1046 1092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                              attribute_ids\n",
       "0  10023b2cc4ed5f68      195 223 289 344 369 587 766 1039 1059\n",
       "1  100fbe75ed8fd887                                   231 1039\n",
       "2  101b627524a04f19                         79 263 420 498 784\n",
       "3  10234480c41284c6           13 147 553 738 776 830 1006 1046\n",
       "4  1023b0e2636dcea8  147 283 322 584 698 813 896 954 1046 1092"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = pd.DataFrame({\"id\": [i.split('.')[0] for i in os.listdir('../input/imet-2019-fgvc6/test/')]})\n",
    "prediction = []\n",
    "for i in range(preds.shape[0]):\n",
    "    pred1 = np.argwhere(preds[i] == 1.0).reshape(-1).tolist()\n",
    "    pred_str = \" \".join(list(map(str, pred1)))\n",
    "    prediction.append(pred_str)\n",
    "\n",
    "pred_df[\"attribute_ids\"] = prediction\n",
    "submission = pd.DataFrame(sample[\"id\"]).merge(pred_df, on=\"id\", how=\"left\")\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
