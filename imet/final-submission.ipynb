{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['se_resnet152_288_v2020_oof6124.pt',\n",
       " 'se_resnext101_32x4d_320_v2042_oof6179.pt',\n",
       " 'densenet161_320_v42_oof6079.pt',\n",
       " 'se_resnext101_32x4d_320_v3042_oof6159.pt',\n",
       " 'densenet201_320_v42_oof6041_lb609.pt',\n",
       " 'se_resnet101_288_v42_oof06083_lb617.pt',\n",
       " 'se_resnext101_32x4d_320_v1042_oof6179.pt',\n",
       " 'resnet101_288_v42_oof6083_lb616.pt',\n",
       " 'se_resnext101_32x4d_320_v42_oof6152_lb621.pt',\n",
       " 'se_resnet152_288_v42_oof6094_lb619.pt',\n",
       " 'se_resnext101_32x4d_288_v3_lb623.pt']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(\"../input/imet-weights2/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ResNet101 (288x288; 40fold)\n",
    "  - v42 (LB 0.616): valid_f2_th_0.10: 0.6076048017265678\n",
    "- SEResNet101 (288x288; 10fold)\n",
    "  - v42 (LB 0.617): valid_f2_th_0.10: 0.60830836837079\n",
    "- SEResNet152 (288x288; 10fold)\n",
    "  - v42 (LB 0.619): valid_f2_th_0.10: 0.6094215115199988\n",
    "  - v2020: valid_f2_th_0.09: 0.6124572071297274\n",
    "- SEResNeXt101_32x4d (288x288; 10fold)\n",
    "  - v3 (LB 0.623): valid_f2_th_0.08\n",
    "- DenseNet201 (320x320; 10fold)\n",
    "  - v42 (LB 0.609): valid_f2_th_0.10: 0.6041637785446881\n",
    "- DenseNet161 (320x320; 10fold)\n",
    "  - v42: valid_f2_th_0.11: 0.6079369147281679\n",
    "- SEResNeXt101_32x4d (320x320; 10fold)\n",
    "  - v42 (LB 0.621): valid_f2_th_0.09: 0.6152833096941255\n",
    "  - v1024: valid_f2_th_0.08: 0.617966264921610\n",
    "  - v2024: valid_f2 th_0.08: 0.6179158801859196\n",
    "  - v3024: valid_f2_th_0.09: 0.6159644164340591"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "from functools import partial\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision.models as M\n",
    "from torchvision.transforms import Compose, Normalize, RandomCrop, RandomResizedCrop, RandomHorizontalFlip, ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLASSES = 1103"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use below models\n",
    "- ResNet101\n",
    "  - v42: 0.10\n",
    "- SEResNet101\n",
    "  - v42: 0.10\n",
    "- SEResNet152\n",
    "  - v2020: 0.09\n",
    "- SEResNeXt101_32x4d (288x288)\n",
    "  - v3: 0.08\n",
    "- DenseNet161\n",
    "  - v42: 0.11\n",
    "- SEResNeXt101_32x4d (320x320)\n",
    "  - v1024: 0.08\n",
    "  - v2024: 0.08\n",
    "  - v3024: 0.09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_models = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09125"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = (0.10+0.10+0.09+0.08+0.11+0.08+0.08+0.09) / num_models\n",
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path, item):\n",
    "    image = cv2.imread(f'{path}/{item}.png')\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return Image.fromarray(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TTADataset(Dataset):\n",
    "    def __init__(self, root, ids, size=288, tta=4):\n",
    "        self.root = root\n",
    "        self.ids = ids\n",
    "        \n",
    "        if size == 288:\n",
    "            self.transform = Compose([\n",
    "                RandomCrop(288),\n",
    "                RandomHorizontalFlip(),\n",
    "                ToTensor(),\n",
    "                Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "            ])\n",
    "        elif size == 320:\n",
    "            self.transform = Compose([\n",
    "                RandomResizedCrop(320, scale=(0.6, 1.0), ratio=(0.5625, 1.77777777)),  # 16:9/9:16\n",
    "                RandomHorizontalFlip(),\n",
    "                ToTensor(),\n",
    "                Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "            ])\n",
    "            \n",
    "        self.tta = tta\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids) * self.tta\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item_id = self.ids[idx % len(self.ids)]\n",
    "        image = load_image(self.root, item_id)\n",
    "        image = self.transform(image)\n",
    "        return image, item_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "## Model definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import OrderedDict\n",
    "\n",
    "class SEModule(nn.Module):\n",
    "\n",
    "    def __init__(self, channels, reduction):\n",
    "        super(SEModule, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Conv2d(channels, channels // reduction, kernel_size=1,\n",
    "                             padding=0)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Conv2d(channels // reduction, channels, kernel_size=1,\n",
    "                             padding=0)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        module_input = x\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return module_input * x\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    \"\"\"\n",
    "    Base class for bottlenecks that implements `forward()` method.\n",
    "    \"\"\"\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out = self.se_module(out) + residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class SEBottleneck(Bottleneck):\n",
    "    \"\"\"\n",
    "    Bottleneck for SENet154.\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n",
    "                 downsample=None):\n",
    "        super(SEBottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes * 2, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes * 2)\n",
    "        self.conv2 = nn.Conv2d(planes * 2, planes * 4, kernel_size=3,\n",
    "                               stride=stride, padding=1, groups=groups,\n",
    "                               bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes * 4)\n",
    "        self.conv3 = nn.Conv2d(planes * 4, planes * 4, kernel_size=1,\n",
    "                               bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se_module = SEModule(planes * 4, reduction=reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "\n",
    "class SEResNetBottleneck(Bottleneck):\n",
    "    \"\"\"\n",
    "    ResNet bottleneck with a Squeeze-and-Excitation module. It follows Caffe\n",
    "    implementation and uses `stride=stride` in `conv1` and not in `conv2`\n",
    "    (the latter is used in the torchvision implementation of ResNet).\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n",
    "                 downsample=None):\n",
    "        super(SEResNetBottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False,\n",
    "                               stride=stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, padding=1,\n",
    "                               groups=groups, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se_module = SEModule(planes * 4, reduction=reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "\n",
    "class SEResNeXtBottleneck(Bottleneck):\n",
    "    \"\"\"\n",
    "    ResNeXt bottleneck type C with a Squeeze-and-Excitation module.\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n",
    "                 downsample=None, base_width=4):\n",
    "        super(SEResNeXtBottleneck, self).__init__()\n",
    "        width = math.floor(planes * (base_width / 64)) * groups\n",
    "        self.conv1 = nn.Conv2d(inplanes, width, kernel_size=1, bias=False,\n",
    "                               stride=1)\n",
    "        self.bn1 = nn.BatchNorm2d(width)\n",
    "        self.conv2 = nn.Conv2d(width, width, kernel_size=3, stride=stride,\n",
    "                               padding=1, groups=groups, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(width)\n",
    "        self.conv3 = nn.Conv2d(width, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se_module = SEModule(planes * 4, reduction=reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "\n",
    "class SENet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, groups, reduction, dropout_p=0.2,\n",
    "                 inplanes=128, input_3x3=True, downsample_kernel_size=3,\n",
    "                 downsample_padding=1, num_classes=1000):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        block (nn.Module): Bottleneck class.\n",
    "            - For SENet154: SEBottleneck\n",
    "            - For SE-ResNet models: SEResNetBottleneck\n",
    "            - For SE-ResNeXt models:  SEResNeXtBottleneck\n",
    "        layers (list of ints): Number of residual blocks for 4 layers of the\n",
    "            network (layer1...layer4).\n",
    "        groups (int): Number of groups for the 3x3 convolution in each\n",
    "            bottleneck block.\n",
    "            - For SENet154: 64\n",
    "            - For SE-ResNet models: 1\n",
    "            - For SE-ResNeXt models:  32\n",
    "        reduction (int): Reduction ratio for Squeeze-and-Excitation modules.\n",
    "            - For all models: 16\n",
    "        dropout_p (float or None): Drop probability for the Dropout layer.\n",
    "            If `None` the Dropout layer is not used.\n",
    "            - For SENet154: 0.2\n",
    "            - For SE-ResNet models: None\n",
    "            - For SE-ResNeXt models: None\n",
    "        inplanes (int):  Number of input channels for layer1.\n",
    "            - For SENet154: 128\n",
    "            - For SE-ResNet models: 64\n",
    "            - For SE-ResNeXt models: 64\n",
    "        input_3x3 (bool): If `True`, use three 3x3 convolutions instead of\n",
    "            a single 7x7 convolution in layer0.\n",
    "            - For SENet154: True\n",
    "            - For SE-ResNet models: False\n",
    "            - For SE-ResNeXt models: False\n",
    "        downsample_kernel_size (int): Kernel size for downsampling convolutions\n",
    "            in layer2, layer3 and layer4.\n",
    "            - For SENet154: 3\n",
    "            - For SE-ResNet models: 1\n",
    "            - For SE-ResNeXt models: 1\n",
    "        downsample_padding (int): Padding for downsampling convolutions in\n",
    "            layer2, layer3 and layer4.\n",
    "            - For SENet154: 1\n",
    "            - For SE-ResNet models: 0\n",
    "            - For SE-ResNeXt models: 0\n",
    "        num_classes (int): Number of outputs in `last_linear` layer.\n",
    "            - For all models: 1000\n",
    "        \"\"\"\n",
    "        super(SENet, self).__init__()\n",
    "        self.inplanes = inplanes\n",
    "        if input_3x3:\n",
    "            layer0_modules = [\n",
    "                ('conv1', nn.Conv2d(3, 64, 3, stride=2, padding=1,\n",
    "                                    bias=False)),\n",
    "                ('bn1', nn.BatchNorm2d(64)),\n",
    "                ('relu1', nn.ReLU(inplace=True)),\n",
    "                ('conv2', nn.Conv2d(64, 64, 3, stride=1, padding=1,\n",
    "                                    bias=False)),\n",
    "                ('bn2', nn.BatchNorm2d(64)),\n",
    "                ('relu2', nn.ReLU(inplace=True)),\n",
    "                ('conv3', nn.Conv2d(64, inplanes, 3, stride=1, padding=1,\n",
    "                                    bias=False)),\n",
    "                ('bn3', nn.BatchNorm2d(inplanes)),\n",
    "                ('relu3', nn.ReLU(inplace=True)),\n",
    "            ]\n",
    "        else:\n",
    "            layer0_modules = [\n",
    "                ('conv1', nn.Conv2d(3, inplanes, kernel_size=7, stride=2,\n",
    "                                    padding=3, bias=False)),\n",
    "                ('bn1', nn.BatchNorm2d(inplanes)),\n",
    "                ('relu1', nn.ReLU(inplace=True)),\n",
    "            ]\n",
    "        # To preserve compatibility with Caffe weights `ceil_mode=True`\n",
    "        # is used instead of `padding=1`.\n",
    "        layer0_modules.append(('pool', nn.MaxPool2d(3, stride=2,\n",
    "                                                    ceil_mode=True)))\n",
    "        self.layer0 = nn.Sequential(OrderedDict(layer0_modules))\n",
    "        self.layer1 = self._make_layer(\n",
    "            block,\n",
    "            planes=64,\n",
    "            blocks=layers[0],\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=1,\n",
    "            downsample_padding=0\n",
    "        )\n",
    "        self.layer2 = self._make_layer(\n",
    "            block,\n",
    "            planes=128,\n",
    "            blocks=layers[1],\n",
    "            stride=2,\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=downsample_kernel_size,\n",
    "            downsample_padding=downsample_padding\n",
    "        )\n",
    "        self.layer3 = self._make_layer(\n",
    "            block,\n",
    "            planes=256,\n",
    "            blocks=layers[2],\n",
    "            stride=2,\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=downsample_kernel_size,\n",
    "            downsample_padding=downsample_padding\n",
    "        )\n",
    "        self.layer4 = self._make_layer(\n",
    "            block,\n",
    "            planes=512,\n",
    "            blocks=layers[3],\n",
    "            stride=2,\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=downsample_kernel_size,\n",
    "            downsample_padding=downsample_padding\n",
    "        )\n",
    "        self.avg_pool = nn.AvgPool2d(7, stride=1)\n",
    "        self.dropout = nn.Dropout(dropout_p) if dropout_p is not None else None\n",
    "        self.last_linear = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, groups, reduction, stride=1,\n",
    "                    downsample_kernel_size=1, downsample_padding=0):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=downsample_kernel_size, stride=stride,\n",
    "                          padding=downsample_padding, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, groups, reduction, stride,\n",
    "                            downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups, reduction))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def features(self, x):\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        return x\n",
    "\n",
    "    def logits(self, x):\n",
    "        x = self.avg_pool(x)\n",
    "        if self.dropout is not None:\n",
    "            x = self.dropout(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.last_linear(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.logits(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "class AvgPool(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return F.avg_pool2d(x, x.shape[2:])\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, weights_path, net_cls=M.resnet101):\n",
    "        super().__init__()\n",
    "        self.net = net_cls()\n",
    "        self.net.avgpool = AvgPool()\n",
    "        self.net.fc = nn.Linear(self.net.fc.in_features, N_CLASSES)\n",
    "        self.load_state_dict(torch.load(weights_path)['model'])\n",
    "\n",
    "    def fresh_params(self):\n",
    "        return self.net.fc.parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class DenseNet(nn.Module):\n",
    "    def __init__(self, weights_path, net_cls=M.densenet121):\n",
    "        super().__init__()\n",
    "        self.net = net_cls()\n",
    "        self.avg_pool = AvgPool()\n",
    "        self.net.classifier = nn.Linear(self.net.classifier.in_features, N_CLASSES)\n",
    "        self.load_state_dict(torch.load(weights_path)['model'])\n",
    "\n",
    "    def fresh_params(self):\n",
    "        return self.net.classifier.parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net.features(x)\n",
    "        out = F.relu(out, inplace=True)\n",
    "        out = self.avg_pool(out).view(out.size(0), -1)\n",
    "        out = self.net.classifier(out)\n",
    "        return out\n",
    "    \n",
    "class InceptionNet(nn.Module):\n",
    "    def __init__(self, weights_path, net_cls=M.inception_v3):\n",
    "        super().__init__()\n",
    "        self.net = net_cls()\n",
    "        self.net.fc = nn.Linear(self.net.fc.in_features, N_CLASSES)\n",
    "        self.net.AuxLogits.fc = nn.Linear(self.net.AuxLogits.fc.in_features, N_CLASSES)\n",
    "        self.load_state_dict(torch.load(weights_path)['model'])\n",
    "\n",
    "    def fresh_params(self):\n",
    "        return self.net.fc.parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "#resnet18 = partial(ResNet, net_cls=M.resnet18)\n",
    "#resnet34 = partial(ResNet, net_cls=M.resnet34)\n",
    "#resnet50 = partial(ResNet, net_cls=M.resnet50)\n",
    "resnet101 = partial(ResNet, net_cls=M.resnet101)\n",
    "#resnet152 = partial(ResNet, net_cls=M.resnet152)\n",
    "\n",
    "#densenet121 = partial(DenseNet, net_cls=M.densenet121)\n",
    "#densenet169 = partial(DenseNet, net_cls=M.densenet169)\n",
    "densenet201 = partial(DenseNet, net_cls=M.densenet201)\n",
    "densenet161 = partial(DenseNet, net_cls=M.densenet161)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEResNet50(nn.Module):\n",
    "    def __init__(self, weights_path, pretrained=False, dropout=False, net_cls=None):\n",
    "        super().__init__()\n",
    "        self.net = SENet(SEResNetBottleneck, [3,4,6,3], groups=1, reduction=16,\n",
    "                         dropout_p=None, inplanes=64, input_3x3=False,\n",
    "                         downsample_kernel_size=1, downsample_padding=0,\n",
    "                         num_classes=N_CLASSES)\n",
    "        self.net.avg_pool = AvgPool()\n",
    "        self.load_state_dict(torch.load(weights_path)['model'])\n",
    "        #self.net.last_linear = nn.Linear(self.net.last_linear.in_features, num_classes)\n",
    "\n",
    "    def fresh_params(self):\n",
    "        return self.net.last_linear.parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class SEResNet101(nn.Module):\n",
    "    def __init__(self, weights_path, pretrained=False, dropout=False, net_cls=None):\n",
    "        super().__init__()\n",
    "        self.net = SENet(SEResNetBottleneck, [3,4,23,3], groups=1, reduction=16,\n",
    "                         dropout_p=None, inplanes=64, input_3x3=False,\n",
    "                         downsample_kernel_size=1, downsample_padding=0,\n",
    "                         num_classes=N_CLASSES)\n",
    "        self.net.avg_pool = AvgPool()\n",
    "        self.load_state_dict(torch.load(weights_path)['model'])\n",
    "        #self.net.last_linear = nn.Linear(self.net.last_linear.in_features, num_classes)\n",
    "\n",
    "    def fresh_params(self):\n",
    "        return self.net.last_linear.parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class SEResNet152(nn.Module):\n",
    "    def __init__(self, weights_path, pretrained=False, dropout=False, net_cls=None):\n",
    "        super().__init__()\n",
    "        self.net = SENet(SEResNetBottleneck, [3,8,36,3], groups=1, reduction=16,\n",
    "                         dropout_p=None, inplanes=64, input_3x3=False,\n",
    "                         downsample_kernel_size=1, downsample_padding=0,\n",
    "                         num_classes=N_CLASSES)\n",
    "        self.net.avg_pool = AvgPool()\n",
    "        self.load_state_dict(torch.load(weights_path)['model'])\n",
    "        #self.net.last_linear = nn.Linear(self.net.last_linear.in_features, num_classes)\n",
    "\n",
    "    def fresh_params(self):\n",
    "        return self.net.last_linear.parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class SEResNeXt50_32x4d(nn.Module):\n",
    "    def __init__(self, weights_path, pretrained=False, dropout=False, net_cls=None):\n",
    "        super().__init__()\n",
    "        self.net = SENet(SEResNeXtBottleneck, [3,4,6,3], groups=32, reduction=16,\n",
    "                         dropout_p=None, inplanes=64, input_3x3=False,\n",
    "                         downsample_kernel_size=1, downsample_padding=0,\n",
    "                         num_classes=N_CLASSES)\n",
    "        self.net.avg_pool = AvgPool()\n",
    "        self.load_state_dict(torch.load(weights_path)['model'])\n",
    "        #self.net.last_linear = nn.Linear(self.net.last_linear.in_features, num_classes)\n",
    "\n",
    "    def fresh_params(self):\n",
    "        return self.net.last_linear.parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class SEResNeXt101_32x4d(nn.Module):\n",
    "    def __init__(self, weights_path, pretrained=False, dropout=False, net_cls=None):\n",
    "        super().__init__()\n",
    "        self.net = SENet(SEResNeXtBottleneck, [3,4,23,3], groups=32, reduction=16,\n",
    "                         dropout_p=None, inplanes=64, input_3x3=False,\n",
    "                         downsample_kernel_size=1, downsample_padding=0,\n",
    "                         num_classes=N_CLASSES)\n",
    "        self.net.avg_pool = AvgPool()\n",
    "        self.load_state_dict(torch.load(weights_path)['model'])\n",
    "        #self.net.last_linear = nn.Linear(self.net.last_linear.in_features, num_classes)\n",
    "\n",
    "    def fresh_params(self):\n",
    "        return self.net.last_linear.parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "se_resnet50 = partial(SEResNet50, net_cls=None)\n",
    "se_resnet101 = partial(SEResNet101, net_cls=None)\n",
    "se_resnet152 = partial(SEResNet152, net_cls=None)\n",
    "se_resnext50_32x4d = partial(SEResNeXt50_32x4d, net_cls=None)\n",
    "se_resnext101_32x4d = partial(SEResNeXt101_32x4d, net_cls=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>attribute_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10023b2cc4ed5f68</td>\n",
       "      <td>0 1 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100fbe75ed8fd887</td>\n",
       "      <td>0 1 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101b627524a04f19</td>\n",
       "      <td>0 1 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10234480c41284c6</td>\n",
       "      <td>0 1 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1023b0e2636dcea8</td>\n",
       "      <td>0 1 2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id attribute_ids\n",
       "0  10023b2cc4ed5f68         0 1 2\n",
       "1  100fbe75ed8fd887         0 1 2\n",
       "2  101b627524a04f19         0 1 2\n",
       "3  10234480c41284c6         0 1 2\n",
       "4  1023b0e2636dcea8         0 1 2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv('../input/imet-2019-fgvc6/sample_submission.csv')\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7443, 1103)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_preds = np.zeros((len(sub), N_CLASSES))\n",
    "final_preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 288x288"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TTADataset('../input/imet-2019-fgvc6/test', sub.id.values, size=288, tta=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SEResNet101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = se_resnet101('../input/imet-weights2/se_resnet101_288_v42_oof06083_lb617.pt')\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "all_outputs, all_ids = [], []\n",
    "\n",
    "for imgs, ids in test_loader:\n",
    "    preds = torch.sigmoid(model(imgs.cuda()).detach())\n",
    "    all_outputs.append(preds.cpu().numpy())\n",
    "    all_ids.extend(ids)\n",
    "    \n",
    "test_preds = pd.DataFrame(data=np.concatenate(all_outputs),\n",
    "                          index=all_ids,\n",
    "                          columns=map(str, range(N_CLASSES)))\n",
    "test_preds = test_preds.groupby(level=0).mean()\n",
    "\n",
    "final_preds += test_preds.values\n",
    "del model, test_preds\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SEResNet152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = se_resnet152('../input/imet-weights2/se_resnet152_288_v2020_oof6124.pt')\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "all_outputs, all_ids = [], []\n",
    "\n",
    "for imgs, ids in test_loader:\n",
    "    preds = torch.sigmoid(model(imgs.cuda()).detach())\n",
    "    all_outputs.append(preds.cpu().numpy())\n",
    "    all_ids.extend(ids)\n",
    "    \n",
    "test_preds = pd.DataFrame(data=np.concatenate(all_outputs),\n",
    "                          index=all_ids,\n",
    "                          columns=map(str, range(N_CLASSES)))\n",
    "test_preds = test_preds.groupby(level=0).mean()\n",
    "\n",
    "final_preds += test_preds.values\n",
    "del model, test_preds\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ResNet101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet101('../input/imet-weights2/resnet101_288_v42_oof6083_lb616.pt')\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "all_outputs, all_ids = [], []\n",
    "\n",
    "for imgs, ids in test_loader:\n",
    "    preds = torch.sigmoid(model(imgs.cuda()).detach())\n",
    "    all_outputs.append(preds.cpu().numpy())\n",
    "    all_ids.extend(ids)\n",
    "    \n",
    "test_preds = pd.DataFrame(data=np.concatenate(all_outputs),\n",
    "                          index=all_ids,\n",
    "                          columns=map(str, range(N_CLASSES)))\n",
    "test_preds = test_preds.groupby(level=0).mean()\n",
    "\n",
    "final_preds += test_preds.values\n",
    "del model, test_preds\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SEResNeXt101 32x4d (288)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = se_resnext101_32x4d('../input/imet-weights2/se_resnext101_32x4d_288_v3_lb623.pt')\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "all_outputs, all_ids = [], []\n",
    "\n",
    "for imgs, ids in test_loader:\n",
    "    preds = torch.sigmoid(model(imgs.cuda()).detach())\n",
    "    all_outputs.append(preds.cpu().numpy())\n",
    "    all_ids.extend(ids)\n",
    "    \n",
    "test_preds = pd.DataFrame(data=np.concatenate(all_outputs),\n",
    "                          index=all_ids,\n",
    "                          columns=map(str, range(N_CLASSES)))\n",
    "test_preds = test_preds.groupby(level=0).mean()\n",
    "\n",
    "final_preds += test_preds.values\n",
    "del model, test_preds\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 320x320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TTADataset('../input/imet-2019-fgvc6/test', sub.id.values, size=320, tta=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DenseNet161"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = densenet161('../input/imet-weights2/densenet161_320_v42_oof6079.pt')\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=24, shuffle=False)\n",
    "\n",
    "all_outputs, all_ids = [], []\n",
    "\n",
    "for imgs, ids in test_loader:\n",
    "    preds = torch.sigmoid(model(imgs.cuda()).detach())\n",
    "    all_outputs.append(preds.cpu().numpy())\n",
    "    all_ids.extend(ids)\n",
    "    \n",
    "test_preds = pd.DataFrame(data=np.concatenate(all_outputs),\n",
    "                          index=all_ids,\n",
    "                          columns=map(str, range(N_CLASSES)))\n",
    "test_preds = test_preds.groupby(level=0).mean()\n",
    "\n",
    "final_preds += test_preds.values\n",
    "del model, test_preds\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SEResNeXt101 32x4d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = se_resnext101_32x4d('../input/imet-weights2/se_resnext101_32x4d_320_v1042_oof6179.pt')\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "all_outputs, all_ids = [], []\n",
    "\n",
    "for imgs, ids in test_loader:\n",
    "    preds = torch.sigmoid(model(imgs.cuda()).detach())\n",
    "    all_outputs.append(preds.cpu().numpy())\n",
    "    all_ids.extend(ids)\n",
    "    \n",
    "test_preds = pd.DataFrame(data=np.concatenate(all_outputs),\n",
    "                          index=all_ids,\n",
    "                          columns=map(str, range(N_CLASSES)))\n",
    "test_preds = test_preds.groupby(level=0).mean()\n",
    "\n",
    "final_preds += test_preds.values\n",
    "del model, test_preds\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = se_resnext101_32x4d('../input/imet-weights2/se_resnext101_32x4d_320_v2042_oof6179.pt')\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "all_outputs, all_ids = [], []\n",
    "\n",
    "for imgs, ids in test_loader:\n",
    "    preds = torch.sigmoid(model(imgs.cuda()).detach())\n",
    "    all_outputs.append(preds.cpu().numpy())\n",
    "    all_ids.extend(ids)\n",
    "    \n",
    "test_preds = pd.DataFrame(data=np.concatenate(all_outputs),\n",
    "                          index=all_ids,\n",
    "                          columns=map(str, range(N_CLASSES)))\n",
    "test_preds = test_preds.groupby(level=0).mean()\n",
    "\n",
    "final_preds += test_preds.values\n",
    "del model, test_preds\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = se_resnext101_32x4d('../input/imet-weights2/se_resnext101_32x4d_320_v3042_oof6159.pt')\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "all_outputs, all_ids = [], []\n",
    "\n",
    "for imgs, ids in test_loader:\n",
    "    preds = torch.sigmoid(model(imgs.cuda()).detach())\n",
    "    all_outputs.append(preds.cpu().numpy())\n",
    "    all_ids.extend(ids)\n",
    "    \n",
    "test_preds = pd.DataFrame(data=np.concatenate(all_outputs),\n",
    "                          index=all_ids,\n",
    "                          columns=map(str, range(N_CLASSES)))\n",
    "test_preds = test_preds.groupby(level=0).mean()\n",
    "\n",
    "final_preds += test_preds.values\n",
    "del model, test_preds\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       ...,\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = (final_preds / num_models) > threshold\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in enumerate(tmp):\n",
    "    ids = np.nonzero(row)[0]\n",
    "    # no men but acotors\n",
    "    if (404 in ids) and (813 not in ids):\n",
    "        tmp[i][404] = 0\n",
    "    # max 4 culture labels\n",
    "    #k = 4\n",
    "    #if tmp[i][:398].sum()>k:\n",
    "    #    ids = np.argpartition(-final_preds[i][:398], k)[:k]\n",
    "    #    tmp[i][:398] = 0\n",
    "    #    tmp[i][ids] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in enumerate(tmp):\n",
    "    ids = np.nonzero(row)[0]\n",
    "    sub.iloc[i].attribute_ids = ' '.join([str(x) for x in ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>attribute_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10023b2cc4ed5f68</td>\n",
       "      <td>223 289 343 344 369 587 766 1059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100fbe75ed8fd887</td>\n",
       "      <td>93 231 1039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101b627524a04f19</td>\n",
       "      <td>79 420 784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10234480c41284c6</td>\n",
       "      <td>13 147 480 483 725 738 776 813 830 1046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1023b0e2636dcea8</td>\n",
       "      <td>147 322 584 737 738 776 813 954 1046 1092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                              attribute_ids\n",
       "0  10023b2cc4ed5f68           223 289 343 344 369 587 766 1059\n",
       "1  100fbe75ed8fd887                                93 231 1039\n",
       "2  101b627524a04f19                                 79 420 784\n",
       "3  10234480c41284c6    13 147 480 483 725 738 776 813 830 1046\n",
       "4  1023b0e2636dcea8  147 322 584 737 738 776 813 954 1046 1092"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
